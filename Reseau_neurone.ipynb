{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dominant-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from cleantext import clean\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "saving-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "incomplete-moderator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Label_train_2.csv', '.DS_Store', 'Creation_matrice_Creation.ipynb', 'FinalDBelon.csv', 'Data_train.csv', 'DataNONEL_clean.csv', 'Clean_Tweets_EM.ipynb', 'Creation_matrice_Detection.ipynb', 'README.md', 'DataBase_temporary_creation.csv', 'Tweets_Not_ElonMusk.csv', 'DataBase.csv', '.gitignore', 'Reseau_neurone.ipynb', 'Data_train_2.csv', 'DataElon_clean.csv', 'Vectorisation.ipynb', '.ipynb_checkpoints', 'Label_train.csv', 'Clean_Tweets_NONEM.ipynb', '.git', 'TweetsElonMusk.csv']\n"
     ]
    }
   ],
   "source": [
    "arr = os.listdir('.')\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worldwide-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hasattr(tf, 'function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optical-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train = pd.read_csv(\"Data_train.csv\")\n",
    "Label_train = pd.read_csv(\"Label_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "concerned-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train_2 = pd.read_csv('Data_train_2.csv')\n",
    "Label_train_2 = pd.read_csv(\"Label_train_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "selected-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Construction_modele(Data_train, Label_train, affichage=1):\n",
    "    #Construction couche de neurones\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "    #Mise au bon format des donnes pour le modele\n",
    "    Tweet_1 = Data_train.values\n",
    "    Tweet_2 = Tweet_1.astype(dtype='float32')\n",
    "    Label_1 = Label_train.values\n",
    "    Label_2 = Label_1[:,0].astype(dtype='uint8')\n",
    "    #Ajustement modele et choix de metrique\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "    #Entrainement du modele\n",
    "    model.fit(Tweet_2, Label_2, epochs=18, verbose=affichage)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interesting-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorisation(Data_train, tweet):   #prend un tweet en argument sous la forme d'une string et renvoi son vecteur sous forme d'une database dans l espace vectoriel de la matrice\n",
    "    Vecteurs = Data_train.columns\n",
    "    row = []\n",
    "    \n",
    "    dictionnary = dict()\n",
    "    for mot in Vecteurs:\n",
    "        dictionnary[mot] = 0\n",
    "    \n",
    "    Mot_tweet = tweet.split(\" \")\n",
    "    \n",
    "    for index, mot in enumerate(Mot_tweet):\n",
    "            if mot in Vecteurs:\n",
    "                dictionnary[mot] = index + 1\n",
    "                \n",
    "    row.append(dictionnary)\n",
    "    Data_out = DataFrame(row)\n",
    "    \n",
    "    if Data_out.loc[0].max() != 0:\n",
    "        Data_out.loc[0] = Data_out.loc[0] / Data_out.loc[0].max()\n",
    "    \n",
    "    return Data_out\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-pollution",
   "metadata": {},
   "source": [
    "La fonction detection prend en argument un tweet sous la forme d'un string, le reseau de neurone entraine et la base de donnee d entrainement utilise pour vectorizer le tweet. La fonction renvoi un tuple de la forme\n",
    "\\\n",
    "\\\n",
    "(\"Elon Musk detecte a x%\", 1)\n",
    "\\\n",
    "(\"Indetermine\", 2)\n",
    "\\\n",
    "(\"Pas Elon Musk a x%\", 0)\n",
    "\\\n",
    "\\\n",
    "1 est renvoye ssi x >= 60%\n",
    "\\\n",
    "0 est renvoye ssi x >= 60%\n",
    "\\\n",
    "2 est renvoye ssi la probabilite que ce soit Elon Musk (ou non) soit comprise entre 40% et 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "regular-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(tweet_sentence, model_neurone, Data_train):\n",
    "    tweet_sentence = tweet_sentence.lower()\n",
    "    tweet_sentence = clean(tweet_sentence, no_emoji=True, no_punct=True, no_urls = True, replace_with_url='', no_digits=True, replace_with_digit='', no_currency_symbols=True, replace_with_currency_symbol='')\n",
    "    vecteur_phrase = Vectorisation(Data_train, tweet_sentence)\n",
    "    vecteur = vecteur_phrase.values\n",
    "    vecteur = vecteur.astype(dtype='float32')\n",
    "    if vecteur.sum() == 0:\n",
    "        char = \"Indetermine\"\n",
    "        return (char, 2)\n",
    "    Prediction = model_neurone.predict(vecteur)\n",
    "    if Prediction[0, 1] >= 0.6:\n",
    "        char = \"Elon Musk detecte a \" + str(Prediction[0, 1]) + \"%\"\n",
    "        return (char, 1)\n",
    "    elif Prediction[0,1] >= 0.4:\n",
    "        char = \"Indetermine\"\n",
    "        return (char, 2)\n",
    "    else :\n",
    "        char = \"Pas Elon Musk a \" + str(Prediction[0, 0]) + \"%\"\n",
    "        return (char, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "administrative-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_creation(tweet_sentence, model_neurone, Data_train):\n",
    "    tweet_sentence = tweet_sentence.lower()\n",
    "    tweet_sentence = clean(tweet_sentence, no_emoji=True, no_punct=True, no_urls = True, replace_with_url='', no_digits=True, replace_with_digit='', no_currency_symbols=True, replace_with_currency_symbol='')\n",
    "    vecteur_phrase = Vectorisation(Data_train, tweet_sentence)\n",
    "    vecteur = vecteur_phrase.values\n",
    "    vecteur = vecteur.astype(dtype='float32')\n",
    "    if vecteur.sum() == 0:\n",
    "        return 0\n",
    "    Prediction = model_neurone.predict(vecteur)\n",
    "    return Prediction[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "useful-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecte et rend une estimation du tweet propose et l ajoute a son entrainement\n",
    "#Renvoi lestimation et le nouveau model de neurone entraine apres estimation avec le tweet donne\n",
    "\n",
    "def detection_apprentissage(tweet_sentence, model_neurone, Data_train, Label_train, val=0):\n",
    "    #estimation\n",
    "    (char, val) = detection(tweet_sentence, model_neurone, Data_train)\n",
    "    #re entrainement du reseau de neurones\n",
    "    tweet_sentence = tweet_sentence.lower()\n",
    "    tweet_sentence = clean(tweet_sentence, no_emoji=True, no_punct=True, no_urls = True, replace_with_url='', no_digits=True, replace_with_digit='', no_currency_symbols=True, replace_with_currency_symbol='')\n",
    "    vecteur_phrase = Vectorisation(Data_train, tweet_sentence)\n",
    "    Data_train = pd.concat([Data_train, vecteur_phrase], ignore_index=True)\n",
    "    Data_train.reset_index(drop=True, inplace=True)\n",
    "    label = DataFrame([{'label':val}])\n",
    "    Label_train = pd.concat([Label_train, label], ignore_index=True)\n",
    "    Label_train.reset_index(drop=True, inplace=True)\n",
    "    model = Construction_modele(Data_train, Label_train, affichage=0)\n",
    "    return ((char, val), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "democratic-tablet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3,4)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-explosion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_apprentissage_liste(tweet_liste, model_neurone, Data_train, Label_train, val_list):\n",
    "    Estimat = []\n",
    "    for tweet in tweet_liste:\n",
    "        Estimat.append(detection(tweet, model_neurone, Data_train)[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "crazy-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation des reseaux de neurones avant le dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "reliable-silence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5312\n",
      "Epoch 2/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.6727 - accuracy: 0.6542\n",
      "Epoch 3/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.6461 - accuracy: 0.7289\n",
      "Epoch 4/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.7595\n",
      "Epoch 5/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7827\n",
      "Epoch 6/18\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4769 - accuracy: 0.7995\n",
      "Epoch 7/18\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4270 - accuracy: 0.8188\n",
      "Epoch 8/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.3905 - accuracy: 0.8359\n",
      "Epoch 9/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.3628 - accuracy: 0.8445\n",
      "Epoch 10/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8562\n",
      "Epoch 11/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8618\n",
      "Epoch 12/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.8689\n",
      "Epoch 13/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.2981 - accuracy: 0.8725\n",
      "Epoch 14/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.2878 - accuracy: 0.8771\n",
      "Epoch 15/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.2790 - accuracy: 0.8788\n",
      "Epoch 16/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.2706 - accuracy: 0.8821\n",
      "Epoch 17/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.8870\n",
      "Epoch 18/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.8885\n"
     ]
    }
   ],
   "source": [
    "reseau_neurone_detection = Construction_modele(Data_train, Label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "overall-exposure",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "370/370 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5521\n",
      "Epoch 2/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.6146\n",
      "Epoch 3/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6694\n",
      "Epoch 4/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.7017\n",
      "Epoch 5/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.7197\n",
      "Epoch 6/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7385\n",
      "Epoch 7/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.7559\n",
      "Epoch 8/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7691\n",
      "Epoch 9/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7792\n",
      "Epoch 10/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7935\n",
      "Epoch 11/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8038\n",
      "Epoch 12/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8126\n",
      "Epoch 13/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.4098 - accuracy: 0.8214\n",
      "Epoch 14/18\n",
      "370/370 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8280\n",
      "Epoch 15/18\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.3878 - accuracy: 0.8325\n",
      "Epoch 16/18\n",
      "370/370 [==============================] - 1s 1ms/step - loss: 0.3779 - accuracy: 0.8341\n",
      "Epoch 17/18\n",
      "370/370 [==============================] - 1s 2ms/step - loss: 0.3704 - accuracy: 0.8398\n",
      "Epoch 18/18\n",
      "370/370 [==============================] - 1s 1ms/step - loss: 0.3634 - accuracy: 0.8411\n"
     ]
    }
   ],
   "source": [
    "reseau_neurone_creation = Construction_modele(Data_train_2, Label_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "changing-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debut du dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "printable-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Creation_tweet(nombre_mots_total, phrase, Data_train_2, model_neurone): #renvoi un tweet sous la forme d une phrase \n",
    "    phrase = phrase.lower()\n",
    "    phrase = clean(phrase, no_emoji=True, no_punct=True, no_urls = True, replace_with_url='', no_digits=True, replace_with_digit='', no_currency_symbols=True, replace_with_currency_symbol='')\n",
    "    liste_mot =  phrase.split(\" \")\n",
    "    if nombre_mots_total < len(liste_mot):\n",
    "        print(\"Erreur liste mot plus longue que le tweet prevu, longueur du tweet pris par defaut au nombre de mots\")\n",
    "        nombre_mots_total = len(liste_mot)\n",
    "    nombre_mot_rest = nombre_mots_total - len(liste_mot)\n",
    "    \n",
    "    liste_tweet = liste_mot + rnd.sample(list(Data_train_2.columns), nombre_mot_rest, counts=None)\n",
    "    tweet_pertinent = ' '.join(liste_tweet)\n",
    "    pertinence = detection_creation(tweet_pertinent, model_neurone, Data_train_2)\n",
    "    \n",
    "    for iteration in range(100):\n",
    "        if pertinence > 0.9:\n",
    "            return tweet_pertinent\n",
    "        liste = liste_mot + rnd.sample(list(Data_train_2.columns), nombre_mot_rest, counts=None)\n",
    "        rnd.shuffle(liste)\n",
    "        current_tweet = ' '.join(liste)\n",
    "        current_pertinence = detection_creation(current_tweet, model_neurone, Data_train_2)\n",
    "        if current_pertinence > pertinence:\n",
    "            pertinence = current_pertinence\n",
    "            tweet_pertinent = current_tweet\n",
    "    return current_tweet\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dress-municipality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love i mr madonna actually artpop giant update'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetos = Creation_tweet(8, 'i love madonna', Data_train_2, reseau_neurone_creation)\n",
    "tweetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "parental-hughes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Elon Musk detecte a 0.92738056%', 1)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection(tweetos, reseau_neurone_creation, Data_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue(iteration, nombre_mot ,reseau_neurone_detection, reseau_neurone_creation, Data_train, Data_train_2, Label_train, Label_train_2):\n",
    "    for i in range(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-soccer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-eagle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-costa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-arabic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-gates",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-appliance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-mauritius",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "instrumental-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'I sing every morning in my shower, i love '\n",
    "#reponse = detection(phrase, reseau_neurone_creation, Data_train_2)\n",
    "reponse = detection_apprentissage(phrase, reseau_neurone_detection, Data_train, Label_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "divine-juice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((_, val), _) = reponse\n",
    "val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
