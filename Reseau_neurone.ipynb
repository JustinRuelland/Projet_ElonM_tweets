{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alien-majority",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "southeast-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "above-parallel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Label_train_2.csv', '.DS_Store', 'Creation_matrice_Creation.ipynb', 'FinalDBelon.csv', 'Data_train.csv', 'DataNONEL_clean.csv', 'Clean_Tweets_EM.ipynb', 'Creation_matrice_Detection.ipynb', 'README.md', 'DataBase_temporary_creation.csv', 'Tweets_Not_ElonMusk.csv', 'DataBase.csv', '.gitignore', 'Reseau_neurone.ipynb', 'Data_train_2.csv', 'DataElon_clean.csv', 'Vectorisation.ipynb', '.ipynb_checkpoints', 'Label_train.csv', 'Clean_Tweets_NONEM.ipynb', '.git', 'TweetsElonMusk.csv']\n"
     ]
    }
   ],
   "source": [
    "arr = os.listdir('.')\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chemical-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hasattr(tf, 'function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "special-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train = pd.read_csv(\"Data_train.csv\")\n",
    "Label_train = pd.read_csv(\"Label_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "later-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Construction_modele(Data_train, Label_train):\n",
    "    #Construction couche de neurones\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "    #Mise au bon format des donnes pour le modele\n",
    "    Tweet_1 = Data_train.values\n",
    "    Tweet_2 = Tweet_1.astype(dtype='float32')\n",
    "    Label_1 = Label_train.values\n",
    "    Label_2 = Label_1[:,0].astype(dtype='uint8')\n",
    "    #Ajustement modele et choix de metrique\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "    #Entrainement du modele\n",
    "    model.fit(Tweet_2, Label_2, epochs=18)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loved-context",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.6890 - accuracy: 0.5366\n",
      "Epoch 2/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.6668\n",
      "Epoch 3/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.7264\n",
      "Epoch 4/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.7561\n",
      "Epoch 5/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.7795\n",
      "Epoch 6/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.8016\n",
      "Epoch 7/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8205\n",
      "Epoch 8/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8338\n",
      "Epoch 9/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8459\n",
      "Epoch 10/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8543\n",
      "Epoch 11/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8597\n",
      "Epoch 12/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8662\n",
      "Epoch 13/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8729\n",
      "Epoch 14/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.8770\n",
      "Epoch 15/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.2780 - accuracy: 0.8805\n",
      "Epoch 16/18\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.8823\n",
      "Epoch 17/18\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8872\n",
      "Epoch 18/18\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.2568 - accuracy: 0.8898\n"
     ]
    }
   ],
   "source": [
    "modelll = Construction_modele(Data_train, Label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hearing-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorisation(Data_train, tweet):   #prend un tweet en argument sous la forme d'une string et renvoi son vecteur sous forme d'une database dans l espace vectoriel de la matrice\n",
    "    Vecteurs = Data_train.columns\n",
    "    row = []\n",
    "    \n",
    "    dictionnary = dict()\n",
    "    for mot in Vecteurs:\n",
    "        dictionnary[mot] = 0\n",
    "    \n",
    "    Mot_tweet = tweet.split(\" \")\n",
    "    \n",
    "    for index, mot in enumerate(Mot_tweet):\n",
    "            if mot in Vecteurs:\n",
    "                dictionnary[mot] = index + 1\n",
    "                \n",
    "    row.append(dictionnary)\n",
    "    Data_out = DataFrame(row)\n",
    "    \n",
    "    if Data_out.loc[0].max() != 0:\n",
    "        Data_out.loc[0] = Data_out.loc[0] / Data_out.loc[0].max()\n",
    "    \n",
    "    return Data_out\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-louisiana",
   "metadata": {},
   "source": [
    "La fonction detection prend en argument un tweet sous la forme d'un string, le reseau de neurone entraine et la base de donnee d entrainement utilise pour vectorizer le tweet. La fonction renvoi un tuple de la forme\n",
    "\\\n",
    "\\\n",
    "(\"Elon Musk detecte a x%\", 1)\n",
    "\\\n",
    "(\"Indetermine\", 2)\n",
    "\\\n",
    "(\"Pas Elon Musk a x%\", 0)\n",
    "\\\n",
    "\\\n",
    "1 est renvoye ssi x >= 60%\n",
    "\\\n",
    "0 est renvoye ssi x >= 60%\n",
    "\\\n",
    "2 est renvoye ssi la probabilite que ce soit Elon Musk (ou non) soit comprise entre 40% et 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proprietary-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(tweet_sentence, model_neurone, Data_train):\n",
    "    tweet_sentence = tweet_sentence.lower()\n",
    "    tweet_sentence = clean(tweet_sentence, no_emoji=True, no_punct=True, no_urls = True, replace_with_url='', no_digits=True, replace_with_digit='', no_currency_symbols=True, replace_with_currency_symbol='')\n",
    "    vecteur_phrase = Vectorisation(Data_train, tweet_sentence)\n",
    "    vecteur = vecteur_phrase.values\n",
    "    vecteur = vecteur.astype(dtype='float32')\n",
    "    if vecteur.sum() == 0:\n",
    "        char = \"Indetermine\"\n",
    "        return (char, 2)\n",
    "    Prediction = model_neurone.predict(vecteur)\n",
    "    if Prediction[0, 1] >= 0.6:\n",
    "        char = \"Elon Musk detecte a \" + str(Prediction[0, 1]) + \"%\"\n",
    "        return (char, 1)\n",
    "    elif Prediction[0,1] >= 0.4:\n",
    "        char = \"Indetermine\"\n",
    "        return (char, 2)\n",
    "    else :\n",
    "        char = \"Pas Elon Musk a \" + str(Prediction[0, 0]) + \"%\"\n",
    "        return (char, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_apprentissage(tweet_sentence, model_neurone, Data_train):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "tender-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Elon Musk detecte a 0.91566247%', 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = 'I sing every morning in my shower, i love space and tesla and bitcoin'\n",
    "detection(phrase, modelll, Data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-talent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
