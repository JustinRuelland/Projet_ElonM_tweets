{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "adjusted-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "binary-geology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FinalDBelon.csv', 'Data_train.csv', 'DataNONEL_clean.csv', 'Clean_Tweets_EM.ipynb', 'Creation_matrice_Detection.ipynb', 'Création_matrice_Création.ipynb', 'README.md', 'Tweets_Not_ElonMusk.csv', 'DataBase.csv', '.gitignore', 'Reseau_neurone.ipynb', 'DataElon_clean.csv', 'Vectorisation.ipynb', '.ipynb_checkpoints', 'Label_train.csv', 'Clean_Tweets_NONEM.ipynb', '.git', 'TweetsElonMusk.csv']\n"
     ]
    }
   ],
   "source": [
    "arr = os.listdir('.')\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unauthorized-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataElon = pd.read_csv('DataElon_clean.csv')\n",
    "DataNONElon = pd.read_csv('DataNONEL_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "brave-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(Database_init):\n",
    "    Database = Database_init.copy()   \n",
    "    for i in Database.index:\n",
    "        Database.loc[i, 'tweet'] = str(Database.loc[i, 'tweet']).lower()\n",
    "        if '@' in str(Database.loc[i,\"tweet\"]):\n",
    "            Tweet = Database.loc[i, 'tweet'].split(' ')\n",
    "            for index, mot in enumerate(Tweet):\n",
    "                if '@' in mot:\n",
    "                    del Tweet[index]\n",
    "            Database.loc[i, 'tweet'] = ' '.join(Tweet)\n",
    "        \n",
    "        Database.loc[i, 'tweet'] = clean(Database.loc[i, 'tweet'], no_emoji=True, no_punct=True, no_urls = True, replace_with_url='', no_digits=True, replace_with_digit='', no_currency_symbols=True, replace_with_currency_symbol='')\n",
    "        \n",
    "        \n",
    "    return Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "integrated-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_mot(Liste):\n",
    "    liste = [' '.join(Liste)]\n",
    "    Liste_mots_doublon = liste[0].split(' ')\n",
    "    for index, mot in enumerate(Liste_mots_doublon):\n",
    "        if '@' in mot:\n",
    "            Liste_mots_doublon[index] = ''\n",
    "    Liste_mots = list(set(Liste_mots_doublon))\n",
    "    return Liste_mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "committed-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_matrice(Liste_mots, Liste):\n",
    "    row =[]\n",
    "    \n",
    "    dictionnary = dict()\n",
    "    for mot in Liste_mots:\n",
    "        dictionnary[mot] = 0\n",
    "    \n",
    "    for tweet in Liste:\n",
    "        dictionnary2 = dictionnary.copy()\n",
    "        tweet_actual = tweet.split(\" \")\n",
    "        tweet_actual_clean = []\n",
    "        for mot_tweet in tweet_actual:\n",
    "            if mot_tweet != '':\n",
    "                tweet_actual_clean.append(mot_tweet)\n",
    "        for index, mot in enumerate(tweet_actual_clean):\n",
    "            if mot in Liste_mots:\n",
    "                dictionnary2[mot] = index + 1 \n",
    "        row.append(dictionnary2)\n",
    "    return DataFrame(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "subtle-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_matrice(Dataframe, n_min):\n",
    "    for col in Dataframe.columns:\n",
    "        if len(Dataframe[Dataframe[col] != 0]) < n_min:\n",
    "            Dataframe.drop(columns = col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "general-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(Matrix):\n",
    "    Matrix_out = Matrix.copy()\n",
    "    index = Matrix_out.index\n",
    "    for ind in index:\n",
    "        Matrix_out.loc[ind] = Matrix_out.loc[ind] / Matrix_out.loc[ind].max()\n",
    "    return Matrix_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataElon = cleaner(DataElon)\n",
    "Liste_tweets_EM = DataElon[\"tweet\"].values\n",
    "\n",
    "DataNONElon = cleaner(DataNONElon)\n",
    "DataNONElon.dropna(inplace=True)\n",
    "Liste_tweets_NONEM = DataNONElon[\"tweet\"].values\n",
    "\n",
    "Liste_tweets = np.concatenate((Liste_tweets_EM[:6000], Liste_tweets_NONEM[:6000]))\n",
    "Liste_mots = creation_mot(Liste_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pending-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataBase_EM = creation_matrice(Liste_mots, Liste_tweets_EM[:6000])\n",
    "DataBase_EM.drop(columns = '', axis=1, inplace=True)\n",
    "\n",
    "DataBase_NEM = creation_matrice(Liste_mots, Liste_tweets_NONEM[:6000])\n",
    "DataBase_NEM.drop(columns = '', axis=1, inplace=True)\n",
    "\n",
    "DataBase = pd.concat([DataBase_EM, DataBase_NEM], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_matrice(DataBase, 18)\n",
    "DataBase_word = DataBase.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rajoute une colonne label : 1 pour un Tweet d'Elon Musk, 0 sinon\n",
    "DataBase_word['label'] = (DataBase_word.index < 6000).astype(np.int64)\n",
    "\n",
    "#Supprime les Tweets qui ont des zéros pour toutes les variables\n",
    "L =[]\n",
    "for i in DataBase_word.index:\n",
    "    if DataBase_word.iloc[i, :-1].sum() == 0:\n",
    "        L.append(i)\n",
    "DataBase_word.drop(index = L, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "useful-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataBase_word.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "becoming-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrice_train = DataBase_word.iloc[:,:-1]\n",
    "Label_train = DataBase_word.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "selective-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTrain = normalize(Matrice_train)\n",
    "DataTrain.to_csv(\"Data_train.csv\", index=False)\n",
    "Label_train.to_csv(\"Label_train.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
